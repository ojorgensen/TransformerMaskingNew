{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x29a3ee0d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import plotly.express as px\n",
    "# import plotly.io as pio\n",
    "# import plotly.graph_objects as go\n",
    "# pio.renderers.default = \"notebook_connected\" # or use \"browser\" if you want plots to open with browser\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "from typing import List, Optional, Callable, Tuple, Union\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "import json\n",
    "\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens import utils, HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "\n",
    "# Saves computation time, since we don't need it for the contents of this notebook\n",
    "t.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "gpt2_small = HookedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OV',\n",
       " 'QK',\n",
       " 'T_destination',\n",
       " 'W_E',\n",
       " 'W_E_pos',\n",
       " 'W_K',\n",
       " 'W_O',\n",
       " 'W_Q',\n",
       " 'W_U',\n",
       " 'W_V',\n",
       " 'W_in',\n",
       " 'W_out',\n",
       " 'W_pos',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " 'accumulated_bias',\n",
       " 'add_caching_hooks',\n",
       " 'add_hook',\n",
       " 'add_module',\n",
       " 'add_perma_hook',\n",
       " 'all_composition_scores',\n",
       " 'all_head_labels',\n",
       " 'apply',\n",
       " 'b_K',\n",
       " 'b_O',\n",
       " 'b_Q',\n",
       " 'b_U',\n",
       " 'b_V',\n",
       " 'b_in',\n",
       " 'b_out',\n",
       " 'bfloat16',\n",
       " 'blocks',\n",
       " 'buffers',\n",
       " 'cache_all',\n",
       " 'cache_some',\n",
       " 'call_super_init',\n",
       " 'center_unembed',\n",
       " 'center_writing_weights',\n",
       " 'cfg',\n",
       " 'check_and_add_hook',\n",
       " 'check_hooks_to_add',\n",
       " 'children',\n",
       " 'clear_contexts',\n",
       " 'context_level',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'dataset',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'embed',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'fill_missing_keys',\n",
       " 'float',\n",
       " 'fold_layer_norm',\n",
       " 'fold_value_biases',\n",
       " 'forward',\n",
       " 'from_pretrained',\n",
       " 'from_pretrained_no_processing',\n",
       " 'generate',\n",
       " 'get_buffer',\n",
       " 'get_caching_hooks',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'get_token_position',\n",
       " 'half',\n",
       " 'hook_dict',\n",
       " 'hook_embed',\n",
       " 'hook_points',\n",
       " 'hook_pos_embed',\n",
       " 'hooks',\n",
       " 'init_weights',\n",
       " 'ipu',\n",
       " 'is_caching',\n",
       " 'ln_final',\n",
       " 'load_and_process_state_dict',\n",
       " 'load_sample_training_dataset',\n",
       " 'load_state_dict',\n",
       " 'loss_fn',\n",
       " 'mod_dict',\n",
       " 'modules',\n",
       " 'move_model_modules_to_device',\n",
       " 'name',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'pos_embed',\n",
       " 'process_weights_',\n",
       " 'refactor_factored_attn_matrices',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'remove_all_hook_fns',\n",
       " 'requires_grad_',\n",
       " 'reset_hooks',\n",
       " 'run_with_cache',\n",
       " 'run_with_hooks',\n",
       " 'sample_datapoint',\n",
       " 'set_extra_state',\n",
       " 'set_tokenizer',\n",
       " 'set_use_attn_result',\n",
       " 'set_use_split_qkv_input',\n",
       " 'setup',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'to_single_str_token',\n",
       " 'to_single_token',\n",
       " 'to_str_tokens',\n",
       " 'to_string',\n",
       " 'to_tokens',\n",
       " 'tokenizer',\n",
       " 'tokens_to_residual_directions',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'unembed',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(gpt2_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iter(gpt2_small.blocks[0].ln1.hook_scale.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mnext\u001b[39;49m(x)\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerNormPre(\n",
       "  (hook_scale): HookPoint()\n",
       "  (hook_normalized): HookPoint()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_small.blocks[0].ln2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unembed()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_small.unembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'close',\n",
       " 'gi_code',\n",
       " 'gi_frame',\n",
       " 'gi_running',\n",
       " 'gi_suspended',\n",
       " 'gi_yieldfrom',\n",
       " 'send',\n",
       " 'throw']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(gpt2_small.blocks[0].ln1.hook_scale.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " 'add_hook',\n",
       " 'add_module',\n",
       " 'add_perma_hook',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'bwd_hooks',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'clear_context',\n",
       " 'cpu',\n",
       " 'ctx',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'fwd_hooks',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'layer',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'name',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'remove_hooks',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(gpt2_small.blocks[0].ln1.hook_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerNormPre(\n",
       "  (hook_scale): HookPoint()\n",
       "  (hook_normalized): HookPoint()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_small.ln_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that in GPT2-small, all the layer norms are pre-folded (they only use the mean scaling + variance normalisation. Thanks Neel!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HookedTransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (ln1): LayerNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): LayerNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNormPre(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2700, -0.8441, -0.9387,  ..., -1.2354, -0.5161, -0.1925],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_small.blocks[0].mlp.b_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_small.blocks[0].mlp.W_in[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0972e-02, -2.7837e-02,  8.8836e-03, -1.5953e-02, -5.1291e-02,\n",
       "         6.3734e-02,  3.3048e-02, -5.8478e-04, -2.2426e-02,  2.2042e-02,\n",
       "        -2.5507e-03, -3.3058e-03,  1.0504e-01, -5.4955e-02, -1.0614e-02,\n",
       "        -7.5600e-03, -1.7999e-02,  1.1931e-01,  6.8784e-02, -5.3566e-02,\n",
       "         6.4375e-02, -7.3302e-04,  1.5406e-01, -6.5432e-04,  1.7465e-01,\n",
       "        -5.9878e-02, -1.5193e-02, -1.0737e-01,  8.3636e-02, -5.6585e-02,\n",
       "        -1.9436e-02,  2.0272e-02, -7.3120e-02,  1.1758e-03, -1.0233e-01,\n",
       "         2.4558e-02, -2.0279e-03, -8.6074e-02,  6.6153e-02, -2.4293e-02,\n",
       "        -4.7778e-02, -6.4683e-02,  4.2292e-02,  1.3291e-01,  4.5853e-02,\n",
       "        -8.9516e-02, -1.5959e-02, -8.3357e-02, -6.3525e-03, -1.3907e-02,\n",
       "         6.1648e-02, -1.4339e-01, -3.0570e-03,  1.6816e-02,  2.6809e-02,\n",
       "        -2.5912e-02,  7.4460e-02,  1.4382e-02, -3.2274e-02,  1.7539e-02,\n",
       "        -9.6569e-03,  2.2307e-02, -6.0053e-02,  1.9773e-02, -4.2129e-03,\n",
       "         2.4415e-02, -2.9629e-02,  2.5379e-02, -1.4102e-02, -4.5578e-02,\n",
       "        -1.3963e-02,  1.0500e-02,  1.0584e-01,  8.6799e-02,  1.3119e-02,\n",
       "        -4.2101e-02, -1.5920e-02, -1.0123e-02,  1.6887e-03, -3.7106e-03,\n",
       "        -4.2231e-02, -5.8179e-02, -5.2813e-02,  3.9807e-02, -5.2200e-02,\n",
       "         1.9443e-02, -7.0182e-03,  2.2297e-03, -5.7214e-02, -8.1890e-03,\n",
       "         7.8681e-02,  1.5142e-02, -1.1099e-02, -4.5997e-02, -1.5703e-02,\n",
       "        -6.3440e-02,  2.0158e-02, -1.0784e-02, -4.8245e-04, -2.9592e-02,\n",
       "        -2.2409e-03, -2.1381e-03, -1.8007e-02, -7.7998e-03, -8.1932e-03,\n",
       "         2.2650e-01, -2.7378e-03, -3.0435e-02, -5.9511e-03,  1.1718e-02,\n",
       "        -1.9485e-02,  6.5047e-02,  5.0584e-02,  8.3240e-03,  1.3042e-01,\n",
       "        -6.1577e-02,  2.6491e-02,  2.4696e-02,  1.7287e-02, -7.9462e-03,\n",
       "         1.2722e-01, -1.6012e-02, -1.4897e-02,  8.2060e-02,  2.2838e-02,\n",
       "         1.7568e-02,  5.8933e-03,  2.2741e-02, -8.8814e-03, -7.0176e-02,\n",
       "        -3.0492e-02, -9.6292e-02,  3.1969e-02, -2.4740e-02, -6.0342e-02,\n",
       "        -9.3964e-02, -9.7599e-02,  2.0022e-02,  3.2964e-03, -1.3322e-02,\n",
       "        -1.6064e-02, -4.9387e-02,  2.2597e-02,  6.4398e-02,  1.3746e-01,\n",
       "        -6.4879e-02, -1.2262e-04,  8.1566e-02, -9.8753e-02,  2.0255e-02,\n",
       "         4.1771e-02, -1.0152e-02,  2.8359e-02, -7.6310e-03, -2.1164e-02,\n",
       "        -5.4304e-02, -3.0813e-02, -5.9140e-02, -7.7066e-02, -2.6817e-02,\n",
       "        -1.4075e-03, -7.2940e-02, -8.9092e-03,  3.3614e-02, -5.2202e-02,\n",
       "         1.2581e-02,  2.1140e-02, -8.5000e-03, -4.2821e-02,  6.7594e-02,\n",
       "         3.5187e-02,  7.1821e-02,  1.0006e-02,  2.1002e-02, -3.4553e-02,\n",
       "        -1.0485e-02,  3.1242e-02, -5.5185e-02, -6.2469e-04, -6.2789e-03,\n",
       "         1.4704e-01,  1.7650e-02,  3.4814e-03,  1.7485e-02, -6.7364e-02,\n",
       "         4.4830e-03, -2.2421e-02, -1.0440e-02,  3.2478e-02,  6.7662e-04,\n",
       "         2.0868e-02, -2.3140e-03, -1.2093e-01, -6.6171e-03, -9.6123e-03,\n",
       "         7.2706e-03, -2.7089e-02,  6.3219e-02, -5.8947e-02, -8.6480e-03,\n",
       "        -5.2210e-02, -6.0222e-02, -1.1913e-01, -2.2164e-01,  7.7017e-02,\n",
       "        -4.9419e-02,  1.1831e-01, -4.4274e-02,  8.2551e-03, -1.2831e-01,\n",
       "         2.9106e-02, -3.1726e-02, -9.1867e-02,  1.1158e-02,  1.7012e-01,\n",
       "        -4.2813e-02, -2.0784e-02,  1.4104e-03, -1.2504e-03, -3.6124e-02,\n",
       "         6.8894e-02,  5.7545e-02, -4.7806e-02,  2.9681e-02, -2.4918e-02,\n",
       "        -3.7408e-02, -4.4838e-02,  1.0373e-01,  5.3747e-02, -5.9960e-02,\n",
       "         3.7237e-02, -1.5301e-02, -5.7989e-02,  4.2153e-02,  1.0067e-01,\n",
       "        -7.2118e-03, -1.7313e-01,  1.3025e-01,  2.6822e-02,  2.4986e-02,\n",
       "        -7.9486e-03,  7.9341e-03, -5.1653e-02,  1.3842e-02,  4.3316e-02,\n",
       "         8.0823e-02, -2.6257e-02,  4.9238e-02, -1.7616e-02,  9.9927e-03,\n",
       "         3.3500e-02, -1.0765e-02, -1.5678e-02, -2.6554e-02, -1.5345e-02,\n",
       "         1.6941e-02, -1.1770e-02,  2.1149e-02,  3.6308e-02,  5.3674e-03,\n",
       "        -1.1583e-01,  6.7138e-03,  4.8095e-02,  1.7890e-02, -3.6109e-02,\n",
       "         5.3024e-02, -3.2827e-03,  3.4605e-02, -1.4139e-02, -1.0983e-02,\n",
       "        -6.6470e-03, -5.1189e-03, -8.7519e-02,  5.2168e-02, -6.7604e-03,\n",
       "         2.5719e-02, -8.5361e-03,  7.1366e-02,  4.5562e-02,  1.1673e-02,\n",
       "         4.0078e-02,  3.7649e-02,  6.4661e-02, -1.0163e-02, -4.7042e-03,\n",
       "         5.9847e-03, -7.5065e-02,  1.5829e-01, -3.5690e-04, -1.8856e-04,\n",
       "        -1.9547e-02, -5.5003e-02, -8.3253e-02,  5.8810e-02,  1.0552e-02,\n",
       "         2.9205e-02, -1.0995e-02,  5.7858e-02,  7.3924e-03, -8.8538e-03,\n",
       "         7.9067e-03, -4.3009e-02,  4.4203e-03, -1.3431e-02,  5.0550e-02,\n",
       "        -1.1729e-01,  1.0438e-01, -6.6630e-02,  2.2542e-02,  7.7976e-02,\n",
       "        -8.2579e-02, -9.9882e-03,  4.7667e-02,  1.8955e-01, -1.9707e-02,\n",
       "        -8.9747e-02,  1.0518e-02,  3.7971e-02,  2.9871e-02,  2.2655e-02,\n",
       "         4.3228e-02,  5.5973e-02,  1.3309e-01,  1.5434e-02, -1.7298e-01,\n",
       "        -5.7925e-02,  2.8456e-03,  1.7784e-02, -2.0552e-02,  6.7711e-02,\n",
       "         2.2049e-02, -5.4119e-02,  9.2700e-02, -7.1520e-02, -1.2071e-02,\n",
       "         1.0142e-01, -2.6482e-02, -5.8388e-02, -5.4131e-02, -2.7262e-02,\n",
       "        -7.7209e-02, -4.9387e-02, -4.9797e-02, -1.3085e-03, -1.8512e-03,\n",
       "        -4.0935e-02, -1.3914e-03,  6.4358e-02, -3.9831e-02,  1.2508e-01,\n",
       "        -2.1099e-02,  2.0959e-02, -3.3766e-02,  2.0008e-02, -4.5126e-02,\n",
       "        -2.7359e-02,  5.0712e-02, -8.1507e-02,  4.2115e-02, -1.2369e-01,\n",
       "        -1.7433e-02, -2.8416e-02,  1.2073e-02,  2.1984e-02, -8.1273e-02,\n",
       "         2.5932e-02,  1.1632e-02, -3.3757e-02,  1.0492e-01,  8.4017e-02,\n",
       "        -9.9071e-03, -1.1959e-01, -6.5921e-02, -2.0518e-03,  3.9533e-02,\n",
       "         6.0484e-03,  3.6909e-02, -1.3467e-02, -2.8299e-02, -1.1924e-02,\n",
       "        -1.8282e-02, -1.7138e-01,  9.9168e-03, -6.5396e-03,  2.3028e-02,\n",
       "         1.5294e-02, -1.8758e-02, -2.7152e-02, -9.8394e-02, -4.8922e-02,\n",
       "        -6.7094e-02, -1.7369e-02, -2.7353e-02,  7.9599e-03, -1.2491e-02,\n",
       "        -3.1100e-02, -1.1243e-02,  3.7497e-02, -3.5603e-02,  8.6186e-02,\n",
       "        -6.6845e-02,  2.8232e-02, -3.7090e-02,  8.0733e-02, -1.9928e-01,\n",
       "        -5.0246e-02, -8.5175e-03, -9.3733e-03,  1.5299e-02, -6.6254e-02,\n",
       "         8.8056e-02,  2.9727e-02, -1.7611e-02, -2.2257e-02,  1.3292e-02,\n",
       "        -1.2315e-02,  9.9613e-03, -8.6056e-03, -2.4923e-03,  1.0674e-01,\n",
       "         2.5939e-03, -3.9074e-03, -9.1439e-02, -4.0325e-02, -1.3866e-01,\n",
       "         1.8332e-01, -1.2181e-01, -7.4521e-02, -1.3300e-02, -2.3071e-02,\n",
       "         1.3789e-02, -2.4536e-02, -1.6293e-02,  5.1638e-02,  1.6489e-02,\n",
       "         4.0184e-03, -3.0914e-02,  7.2682e-02, -2.1130e-02, -9.8337e-03,\n",
       "         8.0291e-02,  1.3071e-02, -3.0482e-02, -4.6770e-02,  1.0410e-02,\n",
       "        -5.5004e-03, -6.5351e-03,  3.4255e-03, -7.9502e-02, -7.9359e-03,\n",
       "         1.2697e-02,  2.9436e-03, -4.7506e-02,  7.7218e-04, -7.7232e-02,\n",
       "        -7.1789e-03, -1.0887e-02,  1.6132e-01,  4.4307e-03, -1.4119e-02,\n",
       "        -9.4071e-02,  1.0819e-02,  3.4252e-02, -1.6083e-02,  4.8821e-03,\n",
       "         2.1540e-04, -9.5420e-02,  1.0968e-01, -2.3038e-01, -1.6199e-02,\n",
       "         1.0453e-01,  1.2950e-01,  1.8107e-02,  1.6549e-01, -3.6191e-03,\n",
       "         1.2407e-02,  6.3667e-02,  1.2556e-01,  5.3278e-02, -2.4468e-02,\n",
       "        -1.5719e-03, -1.6356e-02, -1.3767e-02,  3.7449e-02, -5.8106e-03,\n",
       "         1.1109e-02,  8.4455e-02, -7.8317e-03,  3.9840e-02, -1.3434e-02,\n",
       "         9.0583e-02,  5.0870e-03, -1.7034e-01,  5.2901e-03, -3.3830e-02,\n",
       "         4.6380e-02,  5.3186e-02, -4.6367e-03,  1.2644e-02, -5.1195e-02,\n",
       "        -2.4744e-02,  8.7786e-02,  2.4285e-02,  7.1042e-03, -4.4805e-03,\n",
       "        -3.0939e-03, -2.9390e-02, -1.0551e-02,  1.6694e-02,  1.8723e-02,\n",
       "        -4.0222e-02,  9.4076e-03,  1.2733e-02, -1.4764e-02,  6.4401e-02,\n",
       "         3.7595e-02, -4.0232e-02,  3.3779e-02,  6.1556e-02, -1.0600e-01,\n",
       "         8.0337e-02,  2.0681e-01,  2.8400e-02, -1.2057e-02, -3.3026e-02,\n",
       "        -2.1877e-02, -6.0666e-03,  1.0618e-02, -1.4983e-02, -2.7835e-02,\n",
       "        -1.7664e-02, -1.8717e-02,  6.5112e-03,  6.6492e-02,  2.6536e-02,\n",
       "         2.9437e-04, -6.1148e-02, -4.6275e-02,  1.7883e-02, -2.3820e-02,\n",
       "        -3.3052e-03, -9.4344e-02,  7.9341e-02, -1.5996e-02, -8.0683e-03,\n",
       "        -5.8515e-03, -6.3161e-03, -2.9070e-02,  2.9507e-02,  2.6187e-02,\n",
       "        -8.5962e-03, -7.0580e-03,  1.6903e-02, -1.3285e-01,  3.6781e-02,\n",
       "        -9.6165e-02,  4.4598e-02,  5.9495e-03, -1.8142e-02, -3.2070e-02,\n",
       "         7.0761e-02, -5.4821e-02,  8.9138e-03, -9.8257e-02,  5.6438e-02,\n",
       "         3.3667e-02,  7.9069e-03,  1.1413e-02,  1.0086e-02,  2.0016e-02,\n",
       "        -4.3095e-02, -6.4256e-03, -7.6916e-03, -1.6140e-02,  8.4387e-02,\n",
       "        -2.1165e-04, -2.3320e-02, -1.2247e-01,  9.6882e-03,  8.0697e-02,\n",
       "         6.5244e-02, -1.1700e-01, -1.7314e-02, -9.7997e-02,  1.0692e-01,\n",
       "        -1.9492e-02,  1.1140e-01,  3.9164e-02,  3.0291e-02,  4.1763e-02,\n",
       "         4.6288e-02, -1.3622e-01,  3.3612e-02,  3.3608e-02,  2.3100e-02,\n",
       "         8.5313e-02,  2.6024e-02,  4.9514e-02, -8.0765e-03, -4.3440e-02,\n",
       "        -1.4017e-01, -2.8843e-02, -2.4774e-02, -1.5274e-02,  1.5593e-02,\n",
       "         1.9615e-02,  5.4320e-02, -1.5422e-01,  8.9054e-03, -4.6895e-04,\n",
       "        -4.6298e-02,  2.0909e-02, -6.3405e-02,  3.4400e-02,  8.8206e-02,\n",
       "        -4.2967e-03,  1.0506e-02, -1.2046e-02,  2.5828e-02,  3.5792e-02,\n",
       "        -4.6153e-02, -2.2767e-02,  1.6221e-02, -6.1686e-03,  1.4533e-02,\n",
       "        -8.8457e-02,  1.5686e-02,  4.0438e-02,  4.4897e-02, -3.1127e-02,\n",
       "         1.3351e-01, -1.3637e-01, -4.6858e-02,  2.5196e-03, -5.0988e-02,\n",
       "         3.6259e-02,  6.4347e-02, -1.1323e-01,  1.0804e-01,  2.9472e-04,\n",
       "        -1.8048e-02,  1.8139e-02, -5.5380e-04,  8.9700e-03, -1.8533e-02,\n",
       "        -2.4253e-02, -7.9790e-03,  2.4279e-02,  5.7589e-02, -1.1466e-02,\n",
       "        -1.3538e-02, -2.4511e-02,  6.5570e-02,  3.0624e-02,  3.0631e-02,\n",
       "         2.4518e-02, -1.3245e-02,  1.4941e-02, -1.7709e-01,  1.0009e-02,\n",
       "         1.3342e-01, -1.3528e-02,  6.4475e-02,  8.5287e-02, -1.5490e-02,\n",
       "         1.3530e-02, -1.0588e-02,  2.2495e-02,  5.0275e-02, -4.4270e-02,\n",
       "        -7.6548e-03,  8.9296e-02, -1.5616e-02, -1.2464e-01, -1.7386e-02,\n",
       "        -6.9891e-02, -8.1108e-02, -5.6097e-02,  7.9697e-02, -1.2136e-02,\n",
       "        -1.0992e-02, -1.3672e-01,  2.6291e-02, -3.5574e-02, -5.6921e-02,\n",
       "        -2.2506e-02,  8.8779e-03, -1.2167e-01, -3.4007e-04,  5.8385e-02,\n",
       "         4.3204e-03, -9.1476e-02,  1.0560e-01,  2.3976e-02,  5.2205e-02,\n",
       "         4.5054e-02,  1.8276e-01,  1.1014e-01, -5.2653e-02,  3.3263e-03,\n",
       "         1.3507e-02, -3.8252e-02,  8.4902e-02, -4.5624e-04, -2.2475e-02,\n",
       "        -9.5133e-02,  1.3670e-02,  3.4145e-02,  6.1502e-02, -9.3308e-03,\n",
       "        -5.4330e-03,  1.6265e-01, -5.3074e-02, -3.0790e-02, -7.7902e-03,\n",
       "        -1.8428e-02,  4.7221e-02, -2.2041e-02,  9.5214e-04,  5.8960e-02,\n",
       "        -6.7754e-03,  2.4141e-02,  3.0117e-02, -6.6577e-02,  1.5044e-02,\n",
       "         1.0906e-02, -2.5633e-02,  2.7245e-02, -3.4276e-02,  7.3571e-02,\n",
       "        -2.8799e-02,  7.8240e-03, -1.6766e-02, -2.5903e-02,  1.7645e-02,\n",
       "         1.1706e-01, -2.9099e-02,  1.4262e-02,  2.9171e-02, -1.1348e-02,\n",
       "        -2.1878e-02, -1.3791e-01,  3.2511e-02, -2.1355e-02,  2.6867e-02,\n",
       "         3.5397e-03,  2.0870e-03, -6.4588e-02,  3.4873e-02, -2.8491e-02,\n",
       "         1.6263e-02, -9.9488e-02, -6.3367e-02, -7.9046e-02, -1.3809e-02,\n",
       "        -2.7556e-02,  3.0994e-03,  2.1071e-02,  1.4058e-01,  3.9686e-02,\n",
       "         1.4357e-01, -9.1472e-02,  1.8623e-02,  9.6226e-02,  8.5946e-03,\n",
       "         6.0754e-02,  4.0284e-02, -3.5336e-02], requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_small.blocks[0].mlp.W_in[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3067e-02, -1.3846e-02, -7.5037e-03,  1.9777e-01, -8.6101e-02,\n",
       "         3.4741e-01, -5.3429e-03, -1.0845e-03, -6.2113e-02, -9.1335e-02,\n",
       "         2.9534e-02,  1.5386e-01, -3.6974e-01,  2.4484e-01, -1.5712e-01,\n",
       "         5.3124e-02, -1.2660e-02, -1.6937e-02, -5.6665e-02, -1.2858e-02,\n",
       "         1.9126e-01, -7.3946e-02,  4.5079e-02, -6.1845e-03,  2.0435e-01,\n",
       "        -7.5622e-02,  2.4018e-03,  1.6490e-02, -6.4517e-02,  3.4975e-01,\n",
       "         5.7940e-02, -2.9955e-02, -1.5698e-01,  1.6101e-01, -4.3693e-02,\n",
       "        -1.9378e-02, -6.4340e-03, -2.5251e-01, -1.3581e-01, -7.6953e-02,\n",
       "        -2.7399e-01, -3.7754e-01,  3.4305e-01, -1.7915e-01,  2.7598e-02,\n",
       "         3.3047e-01, -2.4168e-01,  1.8506e-01, -1.6470e-03,  1.6554e-02,\n",
       "         1.8673e-02,  2.5340e-01,  9.4257e-03, -4.4691e-02,  6.5146e-03,\n",
       "        -2.0624e-02, -2.3529e-01,  7.0626e-03, -4.1568e-02,  3.1047e-03,\n",
       "         3.4290e-02, -3.1181e-01,  4.9924e-03,  2.9296e-02, -5.8942e-03,\n",
       "        -1.6427e-01, -1.2766e-01, -2.6220e-02,  1.9677e-02,  5.3709e-02,\n",
       "         2.1601e-02, -8.6998e-04,  1.7578e-01,  7.4904e-02, -2.0895e-02,\n",
       "         1.5425e-02,  2.0065e-02,  3.7668e-02,  7.0831e-03, -2.4761e-02,\n",
       "        -6.8542e-02, -9.3931e-03, -3.6453e-02, -1.9698e-02,  7.0685e-02,\n",
       "        -4.0140e-03,  1.0843e-02,  2.8827e-03, -1.5602e-01,  1.7823e-02,\n",
       "        -1.6139e-02, -3.1285e-01,  1.3861e-01,  2.1834e-01,  4.1435e-02,\n",
       "         1.0700e-02,  3.7945e-01,  1.5511e-02, -4.0358e-02,  3.7402e-03,\n",
       "        -7.5335e-02, -7.4390e-04, -3.0429e-02,  8.0387e-03,  1.5377e-01,\n",
       "        -1.1187e-01, -1.0175e-01,  4.6075e-04,  7.7507e-02, -3.0727e-02,\n",
       "        -9.4624e-03, -1.9045e-01, -1.7555e-01, -1.0738e-01,  1.7627e-01,\n",
       "        -2.0294e-01, -9.6481e-04,  1.5287e-02, -2.7283e-01,  1.1664e-02,\n",
       "        -4.5240e-02, -5.2751e-02,  1.2471e-02,  2.0764e-01, -2.4521e-01,\n",
       "         1.5944e-01, -3.5020e-01, -4.1899e-02,  2.1111e-02,  1.2768e-02,\n",
       "        -6.6901e-02,  1.0254e-01, -4.8382e-03,  1.1830e-01, -2.2271e-02,\n",
       "         5.6679e-01,  9.9723e-02,  2.2416e-03, -6.4224e-01,  2.5743e-02,\n",
       "        -1.4696e-01,  1.6543e-01,  1.7669e-01,  1.2394e-01,  2.3137e-01,\n",
       "        -5.2154e-02, -2.3864e-02, -2.2504e-01, -1.1612e-01,  1.1266e-02,\n",
       "         9.9906e-02,  6.4436e-03, -6.0923e-03, -2.7632e-03, -8.5591e-02,\n",
       "        -2.1210e-01, -1.0417e-01, -1.8686e-01, -2.9235e-01, -1.3897e-01,\n",
       "        -1.1657e-02, -1.3332e-01, -7.3965e-02,  2.4735e-02, -4.2904e-02,\n",
       "         1.5756e-01, -1.6801e-01,  7.5521e-03, -1.9227e-01,  1.5443e-01,\n",
       "         3.6286e-02,  2.3755e-01,  8.7993e-03, -2.0012e-02, -1.6864e-02,\n",
       "        -4.3347e-02, -4.2478e-02, -5.2927e-02,  1.9941e-03, -1.2794e-01,\n",
       "        -2.3720e-02, -4.6653e-01, -1.1099e-02,  1.2592e-02,  2.2724e-01,\n",
       "        -1.8632e-01,  7.6437e-02,  4.2014e-03, -2.5955e-01, -1.4267e-02,\n",
       "        -1.2474e-01,  4.0988e-02,  1.8051e-01, -1.7475e-02, -9.2715e-02,\n",
       "         1.2197e-02, -6.0938e-02, -1.0065e-01,  1.7296e-01, -2.0675e-03,\n",
       "        -3.9666e-02,  2.4453e-03, -2.1984e-01,  1.1763e-01,  2.3547e-01,\n",
       "        -3.9630e-01,  1.1675e-01,  3.0464e-01,  1.9661e-02, -4.7954e-02,\n",
       "        -1.9308e-02,  3.0952e-03,  6.0183e-02,  3.8364e-03, -2.3115e-01,\n",
       "        -1.5430e-01,  7.6592e-03,  1.3777e-01, -8.7053e-04,  2.0778e-01,\n",
       "         1.1192e-01, -8.1151e-02, -1.0668e-01,  4.3689e-02, -2.9703e-02,\n",
       "         1.3757e-01,  3.4815e-01,  3.3260e-02, -4.3706e-01, -2.0930e-02,\n",
       "         3.4339e-01, -2.7234e-02, -1.7978e-01, -3.8393e-02, -3.2043e-02,\n",
       "        -2.0677e-02, -8.5062e-02, -2.6531e-01,  1.6534e-02,  2.9178e-03,\n",
       "         3.4460e-03, -3.0055e-02, -1.4382e-01,  1.8705e-01, -5.3242e-02,\n",
       "         3.6942e-02,  4.8941e-03,  5.4285e-04,  1.2297e-01,  1.4854e-02,\n",
       "         1.6857e-01,  5.2789e-03, -2.7885e-02,  9.7330e-03, -4.4212e-02,\n",
       "         3.5327e-02, -1.1640e-01, -2.7521e-01,  1.7166e-01, -3.8065e-02,\n",
       "         2.4335e-01, -4.1788e-03, -7.9879e-02, -1.3927e-01, -1.8924e-01,\n",
       "        -2.2162e-01, -3.9920e-03, -5.4027e-03, -8.2236e-03, -1.2628e-03,\n",
       "         5.7971e-03,  6.4610e-03,  9.5482e-02, -9.5804e-02, -3.9797e-03,\n",
       "         3.1616e-01,  6.1131e-03,  1.2004e-01, -2.1881e-01, -2.6946e-01,\n",
       "        -1.3738e-01, -1.0972e-01,  5.0601e-02, -3.5682e-03, -1.3307e-01,\n",
       "         8.5243e-03, -1.7374e-02,  1.5842e-01,  5.9420e-03,  6.9369e-03,\n",
       "        -2.3452e-02, -2.4087e-01, -3.8547e-01, -2.4842e-02,  1.8154e-02,\n",
       "         2.1207e-01,  1.5158e-01,  1.9543e-01, -1.9300e-01,  4.8970e-02,\n",
       "        -4.7467e-02, -1.5462e-01, -1.6785e-02,  1.7815e-02,  8.0509e-02,\n",
       "         2.1918e-01,  1.6186e-01,  1.7753e-01,  3.4338e-02,  2.0768e-01,\n",
       "         2.7423e-01, -6.6658e-04, -1.1333e-01,  1.8907e-01, -8.7905e-02,\n",
       "         2.5691e-01, -1.7213e-02,  2.1080e-01,  9.3170e-02,  7.3656e-02,\n",
       "        -4.7136e-02,  2.3468e-01, -3.3000e-01,  4.9509e-02,  5.6638e-03,\n",
       "         1.2627e-01,  6.5715e-03,  1.4022e-01,  2.4070e-03,  8.8401e-02,\n",
       "         1.4097e-01,  1.4016e-01, -5.3957e-02,  9.7783e-02, -3.7723e-01,\n",
       "         1.3432e-01, -7.0805e-03,  5.7975e-01,  3.1508e-01,  8.3904e-03,\n",
       "         2.2556e-01,  2.7261e-02,  4.2997e-01,  1.2117e-02,  9.3994e-03,\n",
       "        -4.6847e-02, -1.3368e-01, -5.4974e-02,  1.3421e-01,  1.1958e-01,\n",
       "        -1.1309e-01,  1.7006e-04,  9.5128e-03, -7.1475e-02, -1.9922e-01,\n",
       "        -1.6432e-01, -1.1636e-03,  1.2798e-01, -2.2391e-01, -1.6785e-01,\n",
       "        -2.2099e-02,  1.3792e-03,  1.1096e-01,  2.8122e-01, -9.0992e-02,\n",
       "         4.3619e-03, -5.5601e-02,  1.4094e-02, -4.9577e-01,  1.1934e-01,\n",
       "         1.0863e-02, -2.0037e-01, -3.5082e-02, -5.6135e-03,  1.9174e-02,\n",
       "         3.5014e-03,  7.2637e-04, -3.3181e-03,  9.9405e-02,  1.5489e-03,\n",
       "        -7.0600e-02,  1.8833e-01,  2.1857e-01, -1.4883e-02,  1.7649e-02,\n",
       "        -6.0386e-03, -2.9868e-02, -1.5319e-01,  6.8177e-02, -8.8239e-03,\n",
       "         1.7183e-02,  4.6273e-02,  7.9291e-02, -7.9962e-03,  1.3318e-01,\n",
       "        -3.2915e-02,  9.9137e-04,  4.4428e-01, -1.6682e-01, -4.2989e-02,\n",
       "         1.3183e-01, -4.8612e-02,  5.4856e-04,  1.8736e-01, -2.4756e-01,\n",
       "        -1.3611e-01, -2.9178e-01,  6.9153e-02,  1.0036e-01, -6.9437e-02,\n",
       "         1.4002e-01, -4.7969e-02, -1.1475e-01,  2.3774e-02, -5.4159e-03,\n",
       "         1.4328e-02,  2.4106e-01, -3.2524e-03,  1.0333e-02,  1.1345e-01,\n",
       "        -3.8396e-03, -8.2872e-03,  2.3855e-01, -2.6455e-01, -5.0849e-02,\n",
       "        -2.7162e-01, -1.2768e-03, -1.7533e-01, -5.7647e-02,  9.0353e-02,\n",
       "         1.8476e-02, -1.2418e-01,  2.3049e-01,  5.7687e-02, -1.4655e-01,\n",
       "         1.7100e-02,  2.7887e-01, -9.6337e-02,  9.7615e-04, -6.9055e-03,\n",
       "         1.4794e-01, -3.0100e-02, -1.9313e-02,  2.6470e-02, -1.5266e-02,\n",
       "        -6.5486e-02,  4.8115e-02,  5.7848e-03,  1.2223e-01, -4.4358e-02,\n",
       "         1.9558e-03,  1.0696e-01,  1.9926e-01, -6.2983e-03,  1.3561e-01,\n",
       "        -1.2291e-02, -2.7922e-03, -2.5498e-02, -2.2099e-01,  1.9837e-03,\n",
       "         5.7784e-02,  5.0785e-02, -8.3340e-02,  1.0007e-01,  2.5504e-07,\n",
       "         3.5793e-03, -2.6415e-01,  1.0576e-01, -1.6490e-01,  4.8385e-02,\n",
       "         6.1289e-02, -1.4244e-01, -5.4050e-02, -1.7924e-01, -8.9955e-02,\n",
       "         4.7437e-01, -1.2823e-01, -1.4038e-01,  5.3345e-02,  3.6324e-02,\n",
       "        -3.8967e-03,  4.5393e-03, -9.4968e-03,  2.4851e-01, -9.7960e-03,\n",
       "         4.0802e-02, -1.0021e-01,  1.1724e-01, -1.2572e-03, -1.0936e-01,\n",
       "         7.3875e-02,  1.7574e-02, -3.1922e-01,  1.5394e-01, -1.9637e-03,\n",
       "         3.0403e-01, -2.9441e-04, -2.7892e-03,  4.8606e-02,  1.3214e-02,\n",
       "         3.8909e-02, -2.0585e-01,  8.6038e-03, -9.2168e-03,  2.5576e-02,\n",
       "         2.4368e-03, -8.4173e-03,  5.2377e-02,  8.6315e-03, -7.8835e-02,\n",
       "         7.8977e-02, -4.1554e-02,  1.0548e-02, -4.8172e-02,  8.2377e-03,\n",
       "         2.1105e-03,  1.8629e-01,  1.4223e-01, -3.4109e-03, -8.4940e-02,\n",
       "        -1.8716e-01, -1.4039e-01,  4.3464e-02,  1.3399e-01, -4.6223e-01,\n",
       "         2.2353e-02,  3.7700e-03,  6.7260e-03, -1.7147e-03, -1.7533e-01,\n",
       "        -1.1558e-01, -7.4803e-02, -5.6709e-02, -1.2928e-02, -1.8867e-01,\n",
       "         1.8282e-02, -1.9937e-02,  8.0178e-02, -1.6030e-02,  6.1046e-02,\n",
       "        -8.5328e-04, -3.1847e-02,  2.7297e-01, -1.8476e-02, -4.1884e-02,\n",
       "        -1.2922e-01,  2.8925e-01,  6.0154e-02, -1.4352e-01, -5.8710e-03,\n",
       "         3.3254e-01, -1.1251e-02, -1.4868e-01, -5.9084e-02, -4.1245e-03,\n",
       "         1.1046e-01, -3.6603e-01, -1.7051e-01, -3.0744e-01,  8.7779e-02,\n",
       "         4.0767e-02, -1.4124e-01,  1.9041e-01,  9.1293e-02,  8.2718e-02,\n",
       "        -3.4746e-02, -8.7354e-04,  2.7665e-02,  9.5992e-03, -1.4858e-03,\n",
       "         1.1983e-01,  3.7026e-03, -2.7519e-01,  1.2917e-01, -9.9991e-02,\n",
       "         5.6280e-03,  4.0690e-01, -5.1042e-01, -5.5773e-03, -2.8379e-02,\n",
       "         1.0027e-01, -1.0005e-01, -1.8103e-02, -3.3524e-01, -1.9392e-01,\n",
       "         1.4603e-01, -7.2415e-02,  9.3564e-03,  6.5020e-03,  2.1705e-01,\n",
       "         6.1974e-02,  1.7653e-02,  8.3422e-02, -3.1924e-02, -2.9714e-02,\n",
       "        -3.3314e-01, -2.2156e-01,  5.5411e-02, -2.5212e-01,  3.8395e-01,\n",
       "        -1.7127e-01, -1.8335e-01,  4.2434e-02,  1.3993e-01,  1.5566e-02,\n",
       "        -2.4183e-02,  1.9886e-01, -4.2237e-01,  8.4982e-03,  3.3669e-01,\n",
       "         5.0303e-02, -8.5081e-03,  1.3443e-01,  1.9368e-01,  3.6668e-01,\n",
       "        -1.8525e-02, -2.9963e-02,  7.0131e-02, -2.4901e-01,  8.6350e-03,\n",
       "         2.5887e-01,  1.5194e-01,  3.0283e-03,  3.0578e-02, -1.2537e-02,\n",
       "         1.0333e-01,  6.8783e-02, -1.7393e-02, -8.4385e-02,  4.2742e-01,\n",
       "        -1.1070e-01, -5.6399e-02,  1.9733e-01, -5.0306e-02,  1.2872e-01,\n",
       "         1.8029e-02,  3.6638e-01, -2.1517e-01,  5.1959e-02, -7.9981e-03,\n",
       "        -1.5897e-02,  1.0004e-01,  6.1259e-04, -1.7869e-04,  1.6791e-03,\n",
       "         5.9068e-02,  6.3458e-02, -8.8214e-03, -1.8291e-01,  1.1194e-02,\n",
       "         1.4780e-01,  1.4511e-02, -1.2088e-01,  5.6058e-03,  2.4997e-01,\n",
       "         2.4872e-02,  1.7999e-01,  5.4642e-03,  6.8959e-02, -1.9903e-02,\n",
       "         1.6279e-01, -4.4516e-02, -1.2369e-01,  1.6086e-01, -1.4040e-01,\n",
       "         2.9331e-02,  4.6017e-02, -3.4751e-02,  2.3213e-01, -7.4328e-02,\n",
       "         8.6599e-03,  1.5138e-02,  2.2597e-01,  1.5295e-01,  1.8421e-02,\n",
       "        -1.1219e-01, -1.4736e-01, -1.5481e-01,  1.2311e-01, -1.5503e-04,\n",
       "         1.0780e-01, -2.1726e-01,  1.9684e-01,  1.9393e-01, -1.4005e-01,\n",
       "         4.2229e-03, -2.7219e-01,  9.2642e-02, -3.4081e-02, -1.9999e-01,\n",
       "        -4.2072e-01, -9.2807e-02,  1.0664e-01, -2.5418e-01, -5.4615e-02,\n",
       "         1.1688e-01, -4.5998e-01, -4.0463e-01,  1.6738e-01, -1.8237e-02,\n",
       "        -2.6215e-01, -8.2639e-03,  5.1551e-02, -1.7759e-02, -2.5486e-03,\n",
       "        -1.3525e-04,  5.5286e-03,  6.2886e-03,  1.1719e-01, -1.0587e-02,\n",
       "         1.2225e-02, -3.3201e-01,  1.4867e-01, -7.2016e-02, -1.6318e-01,\n",
       "        -1.0639e-01, -3.8431e-01,  2.7002e-02, -2.2039e-04, -4.0839e-02,\n",
       "        -3.6305e-02, -2.8023e-02,  1.6735e-02,  4.1250e-02, -3.3580e-02,\n",
       "        -6.2910e-02,  9.6081e-03,  4.2116e-02, -6.5161e-02,  2.3599e-01,\n",
       "         1.6242e-02,  2.9000e-01,  7.9043e-02, -3.3598e-02,  2.7171e-01,\n",
       "         9.5993e-02,  1.4401e-01,  8.0341e-02,  7.2210e-02,  5.7115e-03,\n",
       "        -1.3155e-03, -1.4012e-01, -5.0287e-03,  5.9729e-02, -2.3399e-02,\n",
       "        -3.8877e-03, -5.1093e-03, -2.5701e-01,  4.1847e-02,  2.4467e-02,\n",
       "        -5.7223e-02, -9.7656e-02,  4.3722e-01, -6.9669e-04,  3.9677e-03,\n",
       "         1.4789e-02, -3.9813e-03,  3.7890e-02,  4.5293e-01,  5.0217e-02,\n",
       "         4.4591e-02, -6.7383e-02,  1.2162e-02, -1.4376e-01, -1.7416e-03,\n",
       "         2.0378e-01,  1.6077e-01,  1.2691e-03], requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_small.blocks[0].mlp.W_in[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tran-mask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
